<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.6"/>
<title>Doxygen: Main Page</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() {
    if ($('.searchresults').length > 0) { searchBox.DOMSearchField().focus(); }
  });
</script>
<link rel="search" href="search-opensearch.php?v=opensearch.xml" type="application/opensearchdescription+xml" title="Doxygen"/>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Doxygen
   </div>
  </td>
   <td>        <div id="MSearchBox" class="MSearchBoxInactive">
          <div class="left">
            <form id="FSearchBox" action="search.php" method="get">
              <img id="MSearchSelect" src="search/mag.png" alt=""/>
              <input type="text" id="MSearchField" name="query" value="Search" size="20" accesskey="S" 
                     onfocus="searchBox.OnSearchFieldFocus(true)" 
                     onblur="searchBox.OnSearchFieldFocus(false)"/>
            </form>
          </div><div class="right"></div>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.6 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('index.html','');});
</script>
<div id="doc-content">
<div class="header">
  <div class="headertitle">
<div class="title">Doxygen Documentation</div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><b>The Viola Jones Face Detection Algorithm</b></p>
<p>WANG Yi-Qing, <a href="#" onclick="location.href='mai'+'lto:'+'yiq'+'in'+'g.w'+'an'+'g@p'+'ol'+'yte'+'ch'+'niq'+'ue'+'.ed'+'u'; return false;">yiqin<span style="display: none;">.nosp@m.</span>g.wa<span style="display: none;">.nosp@m.</span>ng@po<span style="display: none;">.nosp@m.</span>lyte<span style="display: none;">.nosp@m.</span>chniq<span style="display: none;">.nosp@m.</span>ue.e<span style="display: none;">.nosp@m.</span>du</a>, ENS Cachan</p>
<h1>List of Source Files </h1>
<p>This source code creates five command line programs.</p>
<ul>
<li><em><a class="el" href="de/dc7/train_8cpp.html" title="command line for training a viola jones cascade detector ">train.cpp</a></em>: Commandline program that performs cascade training</li>
<li><em><a class="el" href="d9/d6b/detect_8cpp.html" title="command line for the viola jones face detector ">detect.cpp</a></em>: Commandline program that performs face detection</li>
<li><em><a class="el" href="de/d6e/class_train_examples.html">TrainExamples</a>.{cpp,h}</em>: Implements a class for Adaboosting main routine: adaboost()</li>
<li><em><a class="el" href="d2/d27/class_detector.html">Detector</a>.{cpp,h}</em>: Implements a class for storing the trained cascade for face detection</li>
<li><em>detectUtil.{cpp,h}</em>: Implements the main routine for face detection: <a class="el" href="d0/d4c/detect_util_8h.html#a3b23deb4a706e26f490ecd3e3ea2fac2" title="detect faces on an image ">scan()</a></li>
<li><em>commonUtil.{cpp,h}</em>: Implements general utilities such as an Eigen wrapper for PNG image IO</li>
<li><em>boostUtil.{cpp,h}</em>: Implements the main routine for cascade construction: <a class="el" href="dd/ddd/boost_util_8cpp.html#a85b650e0144234e9460732c21c541888" title="train a cascade, see the definition of trainParams ">train()</a></li>
<li><em>io_png.{c.h}</em>: Image input and output for PNG</li>
<li><em>startTraining.sh</em>: a bash script for cascade training. It creates several input files for <a class="el" href="dd/ddd/boost_util_8cpp.html#a85b650e0144234e9460732c21c541888" title="train a cascade, see the definition of trainParams ">train()</a></li>
<li><em>getParameters.sh</em>: a bash script for monitoring the training process</li>
</ul>
<h1>Compiling </h1>
<p>The code has been tested with g++ 4.6.3 under Ubuntu and no warning or error was issued.</p>
<p><em>libpng</em> is required as well as the Eigen library. The latter will be automatically downloaded when the code is compiled for the first time, which, however, requires <em>wget</em> to work properly on your system. If it is not the case, please manually download the latest Eigen from its official website <em><a href="http://eigen.tuxfamily.org/index.php?title=Main_Page">http://eigen.tuxfamily.org/index.php?title=Main_Page</a></em>, unpack it, rename it to <em>eigen</em> and move it in the current folder.</p>
<p>To compile, type <code>make OMP=1</code> should the parallelization be enabled. Otherwise, simply type <code>make</code>.</p>
<p>RELEASE is the default mode in the makefile. However, VERSION can be set to DEBUG for testing.</p>
<h1>How to train a cascade </h1>
<p>Unpack the tarballs and issue ./startTraining.sh which will download the required dataset</p>
<p>When asked at the prompt</p>
<blockquote class="doxtable">
<p>start training right away? y/n</p>
<p></p>
</blockquote>
<p>type <em>n</em> to defer the training run to a later time, in which case run the same script again and the required data and folders already in place will be used. Otherwise, type <em>y</em>.</p>
<p>The learned cascade will be stored in <em>Detector.cxx</em>. To use it, rename it <em><a class="el" href="d1/ddb/_detector_8cpp.html" title="face detector data ">Detector.cpp</a></em> and compile again.</p>
<h1>Usage </h1>
<ul>
<li>To run the executable <em>train</em>, issue</li>
</ul>
<blockquote class="doxtable">
<p>./train &gt; trainLog 2&gt;&amp;1 &amp;</p>
<p></p>
</blockquote>
<p>so that the training process is logged to trainLog. It may also be accessed with getParameters.sh, intended to summarize the overall training progress, including accumulated false positive rates at each layer and the committee size per layer.</p>
<ul>
<li>To run the executable <em>detect</em>, issue</li>
</ul>
<blockquote class="doxtable">
<p>./detect example.png [number of layers] [threshold]</p>
<p></p>
</blockquote>
<p>where the first optional parameter defines the number of layers to be used in the cascade and the second denotes the robustness threshold introduced in the post-processing section of the article. These parameters default to 31 and 3. example.png refers to the image subject to face detection.</p>
<p>These explanatory instructions are also given if one simply types</p>
<blockquote class="doxtable">
<p>./detect</p>
<p></p>
</blockquote>
<p>Its output includes</p>
<ul>
<li>rotated.png: because two rotated versions of the input image are also used to increase the detection rate, it is one of them and does not constitute a vital part of the final output.</li>
<li>detectedraw.png: raw detection without the post-processing phase.</li>
<li>ppRobust.png: the detected windows resulting from the robustness test described in the article applied to detectedraw.png.</li>
<li>ppSkin.png: the detected windows resulting from the skin test described in the article applied to detectedraw.png.</li>
<li>ppBoth.png: the detected windows resulting from the two previous tests applied to detectedraw.png.</li>
</ul>
<h1>Face <a class="el" href="d2/d27/class_detector.html">Detector</a> </h1>
<p>This source code implements a detector that scans all the square subwindows inside a given image and highlights those presumably having a face</p>
<p>This is an outline of how the face detection is performed in <a class="el" href="d5/dc3/detect_util_8cpp.html" title="common routines for face detection ">detectUtil.cpp</a>:</p>
<p><a class="el" href="d0/d4c/detect_util_8h.html#a3b23deb4a706e26f490ecd3e3ea2fac2" title="detect faces on an image ">scan()</a>, <a class="el" href="d5/dc3/detect_util_8cpp.html" title="common routines for face detection ">detectUtil.cpp</a>: </p>
<pre class="fragment">readInCascade() reads in a trained cascade classifier.

All the image subwindows are tested by tscan().

highlight() marks those detected faces.
</pre><p><a class="el" href="d0/d4c/detect_util_8h.html#acd8dc47b1c40190aba6e2fd40cb01cb4" title="scan the whole image using a cascade ">tscan()</a>, <a class="el" href="d5/dc3/detect_util_8cpp.html" title="common routines for face detection ">detectUtil.cpp</a>: </p>
<pre class="fragment">imread() reads in a gray image. 
In case of a color image, the RGB to grayscale conversion is performed. 

buildIntegralImage() computes the integral image and squared integral image 
of the image to scan so as to accelerate its local sum and variance evaluation.

The main loop examines all the square subwindows inside the image 

    area contains three parameters that characterizes a subwindow with
    (pos_i, pos_j) denoting its upper left corner's coordinates 

    If the subwindow has a standard deviation smaller than FLAT_THRESHOLD, 
    it is considered to be flat and thus labelled as a non-face. Otherwise
    detectFace() runs the subwindow through the cascade. 
</pre><p><a class="el" href="d0/d4c/detect_util_8h.html#ab308ea0b563fc8235cd5311120e627ee" title="detect face in an image subwindow ">detectFace()</a>, <a class="el" href="d5/dc3/detect_util_8cpp.html" title="common routines for face detection ">detectUtil.cpp</a>: </p>
<pre class="fragment">  An empty cascade considers all the subwindows to have a face.

  Otherwise, computeFeature() calculates the subwindow's features required by the 
  decision stumps in the first layer and a weighted vote determines its label. If
  it is declared to be a face, let this subwindow go to the next layer. If not, 
  reject the subwindow.
</pre><h1><a class="el" href="de/d6e/class_train_examples.html">TrainExamples</a> class </h1>
<p>This part of the code implements training example collection and the Adaboost algorithm using the decision stump as its base learner. Note that here Adaboost does not produce a committee, it only adds one more stump to the committee, given the example weights at the time. How many stumps are needed to form a committee is left to <a class="el" href="dd/ddd/boost_util_8cpp.html" title="main training routines for the Viola-Jones algorithm ">boostUtil.cpp</a></p>
<p>adaboost(), <a class="el" href="d6/d73/_train_examples_8cpp.html" title="Training Utils implemented as an cpp object. ">TrainExamples.cpp</a>: </p>
<pre class="fragment">Construct a new decision stump with bestStump().

predictLabel() evaluates how the decision stump fares.

The training examples' weights are adjusted depending on the outcome. 
</pre><p><a class="el" href="de/d6e/class_train_examples.html">TrainExamples()</a>, <a class="el" href="d6/d73/_train_examples_8cpp.html" title="Training Utils implemented as an cpp object. ">TrainExamples.cpp</a>: </p>
<pre class="fragment">Positive examples are provided as a supplementary material, indexed by a variable called 
positiveExamples. readImagesFromPathFile() helps read them in after tossing out those 
blacklisted as false negative by all the previous cascade layers. In absence of such a cascade,
all provided positives are used.

sampleNegatives() takes negative examples from a large image pool made up of grayscale images 
without human faces, in addition to the negatives (or false positives) left by the previous layers. 

The training and validation examples are prepared differently: 

    All the positive training examples are assigned equal weight, positiveTotalWeight/nPositives
    at the outset. Similarly, (1-positiveTotalWeight)/nNegatives for negative training examples.

    The main loop calls computeHaarLikeFeatures() to calculate the training examples' Haar features. 

    writeOrganizedFeatures() then sorts these training examples in ascending order for each feature.
    Sorting is carried out because a decision stump can then be built in linear time.

    Since there is no need to run Adaboost on the validation pool, to save memory, only their integral
    images are calculated to facilitate the generalization error estimation at a later stage. 
</pre><p>sampleNegatives(), <a class="el" href="d6/d73/_train_examples_8cpp.html" title="Training Utils implemented as an cpp object. ">TrainExamples.cpp</a>: </p>
<pre class="fragment">  readImagesFromPathFile() retrieves the existing good negatives, that is, false positives from the 
  previous layers. If there are not enough, negativeImagePaths is read in from which we expect
  to collect new negative examples so that the total number of false positives gets o nNegatives.

  tscan() is hence called to examine these negative images, if a false positive window larger than the example
  size is found, zoomOutNegative() tries to reduce its size so as to make it an acceptable example. If this
  shrunk version turns out be true negative, this larger window is rejected and the search continues.

  To avoid repeated detections on the images no longer able to provide good negatives, their entries are
  deleted from negativeImagePaths if it is determined to be the case. This operation is performed in the 
  routine's final loop.
</pre><h1>Cascade Construction </h1>
<p>This source code implements the multi-layer cascade designed to reduce false positive rate in an iterative fashion.</p>
<p><a class="el" href="dd/ddd/boost_util_8cpp.html#a85b650e0144234e9460732c21c541888" title="train a cascade, see the definition of trainParams ">train()</a>, <a class="el" href="dd/ddd/boost_util_8cpp.html" title="main training routines for the Viola-Jones algorithm ">boostUtil.cpp</a>: </p>
<pre class="fragment">  The inner loop focuses on constructing a new layer whose false positive rate should be maintained below a
  targeted level under one constraint on the layer committee's size. If its committee can no longer grow, 
  the false positive rate is then allowed to rise without sacrificing too much the false negative rate. The 
  highlight of this part is the classifier shift selection. See the accompanying IPOL article for more details.

  The outer loop records the constructed layers and creates Detector.cpp.   </pre> </div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Thu Apr 3 2014 16:46:52 for Doxygen by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.6 </li>
  </ul>
</div>
</body>
</html>
